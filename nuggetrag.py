# -*- coding: utf-8 -*-
"""NuggetRAG.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1EdQKtiPAWYUJyo2zQFNdU-R8GrFh6hdG
"""

api_key="xvVVjjloMV6V2BDgPL5CZottjlAlC6RH"    #Enter your API Key here.

import sqlite3
import pandas as pd
import numpy as np
from sentence_transformers import SentenceTransformer
import faiss
from transformers import AutoTokenizer, AutoModelForSeq2SeqLM
import requests
import os

BASE_DIR = os.path.dirname(os.path.abspath(__file__))

DB_PATH = os.path.join(BASE_DIR, 'restaurant_data.db')
FAISS_INDEX_PATH = os.path.join(BASE_DIR, 'faiss_menu.idx')
DOCS_PATH = os.path.join(BASE_DIR, 'menu_docs.npy')


#DB_PATH = '/Users/jugal.maniar/Desktop/Nugget/restaurant_data.db'
conn = sqlite3.connect(DB_PATH)

restaurants_df = pd.read_sql("SELECT * FROM restaurant", conn)
rest_docs = restaurants_df.apply(lambda r: (
    f"Restaurant: {r['name']}\n"
    f"Location: {r['location']}\n"
    f"Contact: {r['contact']}\n"
    f"Specialties: {r.get('specialty', '')}"
), axis=1).tolist()
restaurants_info = "\n\n".join(rest_docs)

dfs = []
for i in range(1, 6):
    tbl = f"menu_items_{i}"
    dfs.append(pd.read_sql(
        f"SELECT title, description, price, special_feature, veg_type FROM {tbl}",
        conn
    ))
conn.close()

df = pd.concat(dfs, ignore_index=True)
df['text'] = df.apply(lambda r:
    f"Dish: {r['title']}\n"
    f"Price: ‚Çπ{r['price']}\n"
    f"Vegetarian: {'Veg' if r['veg_type'].strip().lower() in ['veg','v'] else 'Non-Veg'}\n"
    f"Special: {'Yes' if r['special_feature'] else 'No'}\n"
    f"Description: {r['description']}",
    axis=1
)
docs = df['text'].tolist()
#print(f"Loaded {len(docs)} menu items.")

embed_model = SentenceTransformer('all-MiniLM-L6-v2')
embeddings = embed_model.encode(docs, show_progress_bar=True, convert_to_numpy=True)
d = embeddings.shape[1]
index = faiss.IndexFlatL2(d)
index.add(embeddings)
faiss.write_index(index, 'FAISS_INDEX_PATH')
np.save(DOCS_PATH, np.array(docs, dtype=object))

def retrieve(query, k=10):
    q_emb = embed_model.encode([query], convert_to_numpy=True)
    D, I = index.search(q_emb, k)
    return [docs[i] for i in I[0]]

tokenizer = AutoTokenizer.from_pretrained('google/flan-t5-base')
model     = AutoModelForSeq2SeqLM.from_pretrained('google/flan-t5-base')

def ask_mistral(prompt, model_name="mistral-tiny", temperature=0.7, api_key=api_key):
    headers = {
        "Authorization": f"Bearer {api_key}",
        "Content-Type": "application/json"
    }
    data = {
        "model": model_name,
        "messages": [{"role": "user", "content": prompt}],
        "temperature": temperature
    }
    resp = requests.post("https://api.mistral.ai/v1/chat/completions", headers=headers, json=data)
    if resp.status_code == 200:
        return resp.json()["choices"][0]["message"]["content"]
    else:
        raise RuntimeError(f"Mistral API error {resp.status_code}: {resp.text}")

def rag_answer(question, k=10, max_length=200):
    contexts = retrieve(question, k=k)
    prompt = (
        "You are a food assistant.\n\n"
        "Here are the restaurant master records:\n"
        f"{restaurants_info}\n\n"
        "Menu Contexts:\n" +
        "\n\n---\n\n".join(contexts) +
        f"\n\nQuestion: {question}\nAnswer:"
    )
    return ask_mistral(prompt)


import streamlit as st

st.set_page_config(page_title="Restaurant Assistant", page_icon="üçΩÔ∏è")
st.title("üçΩÔ∏è Restaurant Menu Assistant")

st.markdown("""
Ask anything about dishes, prices, veg/non-veg options, or where to find a dish.

**Examples:**
- What's the price of a Vodka and where can I get it?
- Show me veg dishes under ‚Çπ300.
- Which restaurant serves pasta?
""")

query = st.text_input("Type your question:", placeholder="e.g., What's the price of a Vodka and where can I get it?")
if query:
    with st.spinner("Thinking..."):
        response = rag_answer(query)
    st.markdown("### üç¥ Answer")
    st.write(response)
